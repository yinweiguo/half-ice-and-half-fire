# half-ice-and-half-fire
Monte Carlo simulation of a site-decorated Ising square lattice

We simulate the effective square-lattice Ising backbone---with linear size $L=120$~\cite{Strecka_PRB_23_decorated_2D} and periodic boundary conditions---obtained after tracing out the decorated spins, which yields a temperature-dependent effective field $h_{\rm eff}(h,T)$ [Eq.~(\ref{heff}]. For each bare field $h$, we first determine the crossover temperature $T_0(h)$ as the unique root of $h_{\rm eff}(h,T_0)=0$ [Eq.~(\ref{eq:T0})], using a bracketing/bisection solver. We then construct a nonuniform temperature grid $T\in[T_{\min},T_{\max}]$ that is refined around both $T_0(h)$ and $T_c^*$ [Eq.~(\ref{eq:Tc})], and run a parallel-tempering (replica-exchange) simulation in temperature. Each replica at temperature $T_r$ evolves with a single-spin heat-bath (Glauber) update \cite{Glauber1963}, implemented with a checkerboard (two-sublattice) sweep for cache-friendly local updates: for each site $i$ we draw $\sigma_i=+1$ with probability $P(\sigma_i{=}+1)=\{1+\exp[-2\beta(J\sum_{j\in nn(i)} \sigma_j+H_r)]\}^{-1}$, where $\beta=1/T_r$ and $H_r=\mu_a\,h_{\rm eff}(h,T_r)$ is the replicaâ€™s (temperature-dependent) field coupling. Replica exchanges between neighboring temperatures are attempted every five sweeps and accepted with the Metropolis criterion \cite{Metropolis1953} generalized to parameter-dependent Hamiltonians (replica exchange) \cite{Hukushima1996}: swapping configurations $(s^{(r)},s^{(r+1)})$ between $(T_r,H_r)$ and $(T_{r+1},H_{r+1})$ is accepted with probability $\min\{1,\exp(\Delta)\}$, where $\Delta=-\beta_r \mathcal{H}(s^{(r+1)};T_r,H_r)-\beta_{r+1}\mathcal{H}(s^{(r)};T_{r+1},H_{r+1})+\beta_r \mathcal{H}(s^{(r)};T_r,H_r)+\beta_{r+1}\mathcal{H}(s^{(r+1)};T_{r+1},H_{r+1})$. After discarding an initial thermalization stage of $n_\mathrm{therm}=20,000$ sweeps, we measure the backbone magnetization $m_a=\langle \sigma_i\rangle$ for $n_\mathrm{measure}=100,000$ sweeps (with convergence tested against $n_\mathrm{therm}=10,000$ and $n_\mathrm{measure}=50,000$) and estimate statistical uncertainties by binning measurements into blocks of 50 sweeps and taking the standard error over block means (blocking analysis) \cite{Flyvbjerg1989}.
